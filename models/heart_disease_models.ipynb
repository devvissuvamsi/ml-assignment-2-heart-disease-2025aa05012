{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad09946d",
   "metadata": {},
   "source": [
    "\n",
    "# Heart Disease Prediction\n",
    "\n",
    "**Dataset:** UCI Heart Disease Dataset  \n",
    "**Problem Type:** Binary Classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38f9b5",
   "metadata": {},
   "source": [
    "## Step 1: Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# Imports and Configurations\n",
    "# ============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59c897",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779747f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset using project root structure\n",
    "df = pd.read_csv(\"../data/heart.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1d34d",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528191cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values.reshape(-1, 1)\n",
    "\n",
    "# Train-test split (manual)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Feature scaling (standardization)\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec16ba",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1378b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, epochs=500):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w = np.zeros((X.shape[1], 1))\n",
    "        self.b = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            z = np.dot(X, self.w) + self.b\n",
    "            y_pred = self.sigmoid(z)\n",
    "\n",
    "            loss = -np.mean(y * np.log(y_pred + 1e-9) + (1 - y) * np.log(1 - y_pred + 1e-9))\n",
    "\n",
    "            dw = np.dot(X.T, (y_pred - y)) / len(y)\n",
    "            db = np.mean(y_pred - y)\n",
    "\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "\n",
    "            preds = (y_pred >= 0.5).astype(int)\n",
    "            acc = np.mean(preds == y)\n",
    "\n",
    "            self.train_losses.append(loss)\n",
    "            self.train_accuracies.append(acc)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(np.dot(X, self.w) + self.b)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ccdb1",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(lr=0.01, epochs=500)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24effe2a",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6: Evaluation Metrics (All Models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    TP, TN, FP, FN = compute_confusion_matrix(y_true, y_pred)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    return accuracy, precision, recall, f1, TP, TN, FP, FN\n",
    "\n",
    "def print_evaluation(y_true, y_pred, model_name):\n",
    "    acc, prec, rec, f1, TP, TN, FP, FN = compute_metrics(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} Evaluation\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-Score : {f1:.4f}\")\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(\"            Pred 0   Pred 1\")\n",
    "    print(f\"Actual 0     {TN:4d}     {FP:4d}\")\n",
    "    print(f\"Actual 1     {FN:4d}     {TP:4d}\")\n",
    "\n",
    "def plot_evaluation_row(y_true, y_proba, y_pred, title):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # 1. Probability distribution\n",
    "    axes[0].scatter(\n",
    "        range(len(y_proba)),\n",
    "        y_proba.flatten(),\n",
    "        c=y_true.flatten(),\n",
    "        cmap='bwr',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axes[0].axhline(0.5, linestyle='--')\n",
    "    axes[0].set_title(f\"{title}: Predicted Probabilities\")\n",
    "\n",
    "    # 2. Confusion matrix\n",
    "    TP, TN, FP, FN = compute_confusion_matrix(y_true, y_pred)\n",
    "    cm = np.array([[TN, FP], [FN, TP]])\n",
    "\n",
    "    axes[1].imshow(cm, cmap='Blues')\n",
    "    axes[1].set_title(f\"{title}: Confusion Matrix\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[1].text(j, i, cm[i, j], ha='center', va='center')\n",
    "\n",
    "    # 3. Metric summary\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if TP + FP else 0\n",
    "    recall = TP / (TP + FN) if TP + FN else 0\n",
    "\n",
    "    axes[2].bar(\n",
    "        ['Accuracy', 'Precision', 'Recall'],\n",
    "        [accuracy, precision, recall]\n",
    "    )\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].set_title(f\"{title}: Metrics\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1dc8b0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7: Visualizations (All Models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c460d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(model):\n",
    "    plt.figure()\n",
    "    plt.plot(model.train_losses, label='Loss')\n",
    "    plt.plot(model.train_accuracies, label='Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Training History')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(y_true, y_pred_proba, y_pred):\n",
    "    plt.figure()\n",
    "    plt.scatter(range(len(y_pred_proba)), y_pred_proba.flatten(), \n",
    "                c=y_true.flatten(), cmap='bwr', alpha=0.6)\n",
    "    plt.axhline(0.5, linestyle='--')\n",
    "    plt.title('Predicted Probabilities')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    TP, TN, FP, FN = compute_confusion_matrix(y_true, y_pred)\n",
    "    cm = np.array([[TN, FP], [FN, TP]])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0,1], ['0','1'])\n",
    "    plt.yticks([0,1], ['0','1'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def plot_evaluation_row(y_true, y_proba, y_pred, title):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # 1. Probability distribution\n",
    "    axes[0].scatter(\n",
    "        range(len(y_proba)),\n",
    "        y_proba.flatten(),\n",
    "        c=y_true.flatten(),\n",
    "        cmap='bwr',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axes[0].axhline(0.5, linestyle='--')\n",
    "    axes[0].set_title(f\"{title}: Predicted Probabilities\")\n",
    "\n",
    "    # 2. Confusion matrix\n",
    "    TP, TN, FP, FN = compute_confusion_matrix(y_true, y_pred)\n",
    "    cm = np.array([[TN, FP], [FN, TP]])\n",
    "\n",
    "    axes[1].imshow(cm, cmap='Blues')\n",
    "    axes[1].set_title(f\"{title}: Confusion Matrix\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[1].text(j, i, cm[i, j], ha='center', va='center')\n",
    "\n",
    "    # 3. Metric summary\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if TP + FP else 0\n",
    "    recall = TP / (TP + FN) if TP + FN else 0\n",
    "\n",
    "    axes[2].bar(\n",
    "        ['Accuracy', 'Precision', 'Recall'],\n",
    "        [accuracy, precision, recall]\n",
    "    )\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].set_title(f\"{title}: Metrics\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b5395",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8: Evaluation & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)\n",
    "plot_training_history(model)\n",
    "print_evaluation(y_train, y_train_pred, \"Training\")\n",
    "plot_evaluation_row(y_train, y_train_proba, y_train_pred, \"Train\")\n",
    "\n",
    "\n",
    "# Testing\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)\n",
    "print_evaluation(y_test, y_test_pred, \"Testing\")\n",
    "plot_evaluation_row(y_test, y_test_proba, y_test_pred, \"Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
